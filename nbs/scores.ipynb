{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../pgsbenchmark/scores.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../pgsbenchmark/scores.py\n",
    "#!/usr/bin/env python\n",
    "\n",
    "\"\"\"\n",
    "PrivacyPreservingMetricsComputer\n",
    "MultiPGSComputer\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "from pysnptools.standardizer import UnitTrained\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "# tqdm = partial(tqdm, position=0, leave=True)\n",
    "tqdm = partial(tqdm, position=0, leave=True, ncols=70, delay=0.3)\n",
    "\n",
    "locals_dt = dict()    \n",
    "\n",
    "\n",
    "class PrivacyPreservingMetricsComputer():\n",
    "    \n",
    "    def __init__(self, *, linkdata, brd, s, Bm, dtype='float32', cov_method='local', \n",
    "                 clear_linkage=True, verbose=True):\n",
    "        \n",
    "        self.linkdata   = linkdata\n",
    "        self.brd        = brd\n",
    "        assert (np.isnan(s).sum()+np.isinf(s).sum()) == 0\n",
    "        self.s          = s\n",
    "        self.Bm         = Bm \n",
    "        self.dtype      = dtype\n",
    "        self.cov_method = cov_method\n",
    "        self.clear_linkage = clear_linkage\n",
    "        self.verbose    = verbose\n",
    "        \n",
    "        self._do_global = False\n",
    "        self._do_local  = False\n",
    "        if cov_method == 'local': # Local Residualized Marginals\n",
    "            self._do_local  = True\n",
    "        elif cov_method == 'global': # Global Residualized Marginals\n",
    "            self._do_global = True\n",
    "        elif cov_method == 'glocal': # Global Local Residualized Marginals\n",
    "            self._do_global = True\n",
    "            self._do_local  = True\n",
    "        else:\n",
    "            raise Exception(f'Option not recognized: \\'{cov_method}\\' ')\n",
    "            \n",
    "    def evaluate(self, debug=False):\n",
    "        \n",
    "        # Load and init variables:\n",
    "        linkdata = self.linkdata\n",
    "        #linkdata = self.linkdata.init() # init, in case required.\n",
    "        brd = self.brd; s = self.s; Bm = self.Bm\n",
    "        bCb = 0.; BmBt = 0.\n",
    "        info_dt = dict()\n",
    "\n",
    "        # Cycle through the blocks:\n",
    "        for i, geno_dt in tqdm(linkdata.reg_dt.items()):\n",
    "            if self.verbose: print(f'PPB: Processing region {i}', end='\\r')\n",
    "\n",
    "            # Ready the LD:\n",
    "            L = linkdata.get_left_linkage_region(i=i)\n",
    "            D = linkdata.get_auto_linkage_region(i=i)\n",
    "            R = linkdata.get_right_linkage_region(i=i)\n",
    "            lr = linkdata.get_left_range_region(i=i)\n",
    "            ar = linkdata.get_auto_range_region(i=i)\n",
    "            rr = linkdata.get_right_range_region(i=i)\n",
    "\n",
    "            # Ready The Weights:\n",
    "            B_L = brd[:,lr[0]:lr[1]].read().val.astype(self.dtype).T\n",
    "            B_D = brd[:,ar[0]:ar[1]].read(dtype=self.dtype).val.T\n",
    "            B_R = brd[:,rr[0]:rr[1]].read(dtype=self.dtype).val.T\n",
    "            B_L = s[lr[0]:lr[1]]*B_L\n",
    "            B_D = s[ar[0]:ar[1]]*B_D\n",
    "            B_R = s[rr[0]:rr[1]]*B_R\n",
    "\n",
    "            # Do the computation:\n",
    "            CB = L.dot(B_L) + D.dot(B_D) + R.dot(B_R)\n",
    "            bCb += (B_D*CB).sum(axis=0)\n",
    "            BmBt += (B_D.T.dot(Bm.iloc[ar[0]:ar[1],:])).T\n",
    "            info_dt[i] = dict(shapeL=L.shape, shapeD=D.shape, shapeR=R.shape, \n",
    "                              lr=lr, ar=ar, rr=rr)\n",
    "\n",
    "            # Pruning to minimize memory overhead:\n",
    "            if (i > 0) and self.clear_linkage:\n",
    "                linkdata.clear_linkage_region(i=i-1)\n",
    "            if (i > 38) & debug:\n",
    "                break\n",
    "                return locals()\n",
    "\n",
    "        # Complete resutls:\n",
    "        linkdata.clear_all_xda()\n",
    "        cols = brd.row.astype(str).flatten()\n",
    "        bCb  = pd.DataFrame(bCb[np.newaxis,:], index=['bCb'], columns=cols)\n",
    "        BmBt = pd.DataFrame(BmBt, index=Bm.columns, columns=cols)\n",
    "        ppbr2_df = (BmBt**2)/bCb.loc['bCb']\n",
    "        res_dt = dict(ppbr2_df=ppbr2_df, bCb=bCb, BmBt=BmBt, info_dt=info_dt, s=s)\n",
    "\n",
    "        return res_dt\n",
    "    \n",
    "# locals_dt = dict()\n",
    "class MultiPGSComputer():\n",
    "    \n",
    "    def __init__(self, *, brd, unscaled=True, verbose=False, dtype='float32', allow_nan=False):\n",
    "        self.brd   = brd\n",
    "        if hasattr(brd, 'val'):\n",
    "            assert np.sum(np.isnan(brd.val)) == 0 \n",
    "        self.unscaled = unscaled\n",
    "        self.verbose = verbose\n",
    "        self.dtype  = dtype\n",
    "        self.allow_nan = allow_nan\n",
    "        \n",
    "    def predict(self, *, srd, prd=None, n_inchunk=1000, stansda=None):\n",
    "            \n",
    "        # Load that PGS (& optionaly phenos)\n",
    "        brd = self.brd\n",
    "        Yhat = np.zeros((srd.shape[0], brd.shape[0]), dtype=self.dtype)        \n",
    "        assert np.all(brd.col.astype(str) == srd.sid)\n",
    "        if prd: \n",
    "            assert np.all(srd.iid == prd.iid)\n",
    "            pda   = prd.read(dtype=self.dtype).standardize()\n",
    "            Ytru  = pda.val\n",
    "            Bm    = np.zeros((srd.shape[1], Ytru.shape[1])) + np.nan\n",
    "        \n",
    "        # Loop through Genome:\n",
    "        stansda_lst = []; start=0\n",
    "        for start in tqdm(range(0, srd.shape[1], n_inchunk)):\n",
    "            stop = min(start+n_inchunk, srd.shape[1])\n",
    "            sda, stansda = srd[:,start:stop].read(dtype=self.dtype).standardize(return_trained=True)\n",
    "            X = sda.val\n",
    "            s = stansda.stats[:,1][:,np.newaxis]; s[np.isinf(s)] = 1\n",
    "            L = brd[:,start:stop].read(dtype=self.dtype).val\n",
    "            B = s*L.T # s seems of little effect on time here, projected loading takes time 200s for HM3 8K betas. for 10k induv.\n",
    "            Yhat += X@B\n",
    "            if prd: Bm[start:stop] = X.T@Ytru\n",
    "            stansda_lst.append(stansda)\n",
    "            \n",
    "        if prd:    \n",
    "            Bm = Bm/Ytru.shape[0]\n",
    "            if not self.allow_nan: assert np.isnan(Bm).sum() == 0\n",
    "            if not self.allow_nan: assert np.isnan(Bm).sum() == 0\n",
    "            Bm = pd.DataFrame(Bm, index=srd.sid, columns=prd.col)\n",
    "            Ytru = pd.DataFrame(Ytru, # Make Ytru a proper dataframe\n",
    "                index=pd.MultiIndex.from_arrays(prd.iid.T, names=('fid','iid')),\n",
    "                columns=prd.col)\n",
    "        else:\n",
    "            Ytru=None; Bm=None\n",
    "            \n",
    "        # Combine Standardizers:\n",
    "        sid     = np.concatenate([stan.sid   for stan in stansda_lst])\n",
    "        assert  np.unique(sid).shape[0] == sid.shape[0]\n",
    "        stats   = np.concatenate([stan.stats for stan in stansda_lst])\n",
    "        stansda = UnitTrained(sid, stats)   \n",
    "        s = stansda.stats[:,1][:,np.newaxis]; s[np.isinf(s)] = 1\n",
    "        \n",
    "        # Create Yhat dataframe:\n",
    "        Yhat  = pd.DataFrame(\n",
    "            data    = Yhat, \n",
    "            index   = pd.MultiIndex.from_arrays(srd.iid.T, names=('fid','iid')),\n",
    "            columns = self.brd.row.astype(str)\n",
    "        ); assert Yhat.isna().sum().sum() == 0\n",
    "        \n",
    "        res_dt = dict(Yhat=Yhat, Bm=Bm, brd=brd, Ytru=Ytru, stansda=stansda, s=s)\n",
    "        \n",
    "        return locals()\n",
    "    \n",
    "    def run(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../pgsbenchmark/scores.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "283.09px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
